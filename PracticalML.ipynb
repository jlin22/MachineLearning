{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating a Hypothesis\n",
    "Model Selection  \n",
    "Validation Set: Use it to select a hyperparmeter. However, if you use it to set one hyperparameter, you cannot use it to set another one.  \n",
    "Bias and Variance  \n",
    "High bias means underfitting. High variance means overfitting.  \n",
    "High bias means both $J_{train}$ and $J_{CV}$ will be high.\n",
    "High variance means $J_{train}$ will be low and $J_{CV}$ will be high.  \n",
    "Have a list of lambdas, test each one on the validation set and choose the one with the lowest $J_{CV}$.  \n",
    "Learning Curves  \n",
    "Plot error as a function of training set size.  \n",
    "Fixes to High Variance: Get more training examples, trying a smaller set of features, decreasing $\\lambda$   \n",
    "Fixes to High Bias: Adding features, adding polynomial features, increasing $\\lambda$  \n",
    "Diagnosing Neural Networks  \n",
    "Fewer parameters means more prone to underfitting and computationally cheaper. More parameters means the opposite. You can use $\\lambda$ to control overfitting.    \n",
    "Use a single layer as you start.  \n",
    "ML System Design  \n",
    "Different Approaches  \n",
    "Gather a lot of data, spend time developing sophisticated features or quick and develop algorithms to process input in different ways  \n",
    "Recommended: Simple quick and dirty algorithm, test early, plot learning curves to diagnose high bias or variance, manually analyze errors on examples in the cross validation set and try to spot a trend.  \n",
    "Error Metrics for Skewed Classes  \n",
    "Skewed Classes- When one class is rare  \n",
    "Precision = $\\frac{tp}{tp + fp}$ (of the positive predictions, which ones were actually positive)\n",
    "Recall = $\\frac{tp}{tp + fn}$ (of the actual positives, which ones did we predict to be positive)  \n",
    "F Score = $\\frac{2FP}{F + P}$  \n",
    "We can trade off precision and recall by increasing or decreasing the threshold.  \n",
    "If you increase the threshold you get higher precision and lower recall (decrease fp, increase fn). If you decrease the threshold you get higher recall and lower precision (decrease fn, increase fp).  \n",
    "Data  \n",
    "Give our features enough information. Think how much information a human would need to make the prediction.  \n",
    "For low bias algorithms, more data is usually better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

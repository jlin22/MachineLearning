{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost Function: J = C(sum of costs) + $\\frac{1}{2}$(L2 weights)  \n",
    "Think of C = $\\frac{1}{\\lambda}$. Decrease C if you want more regularization and increase C if you want less regularization. \n",
    "When C is large, SVM will optimize for largest margin. When C is smaller, SVM will avoid overfitting and be less susceptible to outliers. \n",
    "Kernels  \n",
    "Similarity Kernel: $K(x, z) = \\exp(-\\frac{||x - z||^2}{2\\sigma^2})$  \n",
    "Can either choose landmarks or choose the landmarks to be the points themselves. \n",
    "For landmarks, $h_w(x) = w_1x_1 + w_2x_2 + \\dots + w_nx_n$, where $n$ is number of landmarks.  \n",
    "When landmarks are the points themselves, $n = m$.   \n",
    "Practical Decisions  \n",
    "Hyperparameters  \n",
    "C large for high bias, C small for high variance.  \n",
    "$\\sigma$ large for high variance and $\\sigma$ small for high bias.  \n",
    "Choose C(outliers and val set), choose kernel(amount of data and parameters), $\\sigma^2$ for gaussian kernel\n",
    "Multiclass Classification  \n",
    "When to use SVMs  \n",
    "n >> m, use simple model (linear svm or logistic regression) (model must be simple to match VC dimension)\n",
    "n small and m intermediate, use gaussian kernel (complex nonlinear hypothesis)\n",
    "n small and m large, create more features and use logistic regression or linear svm (need more features to match the VC dimension, have high bias)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
